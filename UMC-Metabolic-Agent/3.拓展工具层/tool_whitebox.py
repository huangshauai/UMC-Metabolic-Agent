# -*- coding: utf-8 -*-
"""
UMC-Metabolic-Agent ç™½ç›’è°ƒè¯•å·¥å…·ï¼ˆæ ¸å¿ƒé€»è¾‘æ‹†è§£+çŠ¶æ€ç›‘æ§+å‚æ•°åˆ†æï¼‰
æ ¸å¿ƒé€»è¾‘ï¼šä»ç™½ç›’è§†è§’æš´éœ²æ™ºèƒ½ä½“å†…éƒ¨çŠ¶æ€ã€åˆ†æ­¥è¿½è¸ªè¿è¡Œæµç¨‹ã€åˆ†æå‚æ•°å½±å“ï¼Œè¾…åŠ©è°ƒè¯•/å­¦ä¹ 
è®¾è®¡åŸåˆ™ï¼šæè‡´é€æ˜ã€åˆ†æ­¥æ‹†è§£ã€æ—¥å¿—è¯¦å°½ã€é€‚é…æ–°æ‰‹ç†è§£å†…éƒ¨é€»è¾‘
"""
import configparser
import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
import traceback
from typing import Dict, Any, List, Callable, Optional
import warnings
warnings.filterwarnings("ignore")
plt.rcParams["font.sans-serif"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False

# å¯¼å…¥æ ¸å¿ƒå·¥å…·å’Œæ¨¡å—
from tool_build import UMCAgent, create_test_data
from data_processing import DataProcessor
from goal_discovery import AutonomousGoalDiscovery
from umc_performance import PerformanceMonitor

class WhiteboxDebugger:
    """UMCæ™ºèƒ½ä½“ç™½ç›’è°ƒè¯•å™¨ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šç›‘æ§/è¿½è¸ª/åˆ†æ/è°ƒè¯•ï¼‰"""
    def __init__(self, umc_agent: UMCAgent, debug_log_dir: str = "./whitebox_logs"):
        """
        åˆå§‹åŒ–ç™½ç›’è°ƒè¯•å™¨
        :param umc_agent: å·²åˆå§‹åŒ–çš„UMCAgentå®ä¾‹
        :param debug_log_dir: ç™½ç›’è°ƒè¯•æ—¥å¿—ç›®å½•
        """
        # å…³è”UMCæ™ºèƒ½ä½“å®ä¾‹
        self.umc_agent = umc_agent
        # åˆå§‹åŒ–è°ƒè¯•æ—¥å¿—ç›®å½•
        self.debug_log_dir = debug_log_dir
        os.makedirs(self.debug_log_dir, exist_ok=True)
        # åˆå§‹åŒ–è°ƒè¯•çŠ¶æ€
        self.debug_history = []
        self.step_trace_log = []
        self.param_analysis_result = {}

    def monitor_module_states(self, save_log: bool = True) -> Dict[str, Any]:
        """
        ç™½ç›’æ ¸å¿ƒï¼šå®æ—¶ç›‘æ§æ‰€æœ‰æ ¸å¿ƒæ¨¡å—çš„å†…éƒ¨çŠ¶æ€
        è¾“å‡ºå†…å®¹ï¼šç¼“å­˜ã€è®¡æ•°ã€é…ç½®ã€å†å²è®°å½•ç­‰å†…éƒ¨å˜é‡
        :param save_log: æ˜¯å¦ä¿å­˜çŠ¶æ€æ—¥å¿—
        :return: æ‰€æœ‰æ¨¡å—çš„çŠ¶æ€æ±‡æ€»
        """
        print("ğŸ” å¼€å§‹ç›‘æ§æ ¸å¿ƒæ¨¡å—å†…éƒ¨çŠ¶æ€...")
        state_summary = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "data_processor": {
                "cache_size": len(self.umc_agent.data_processor.data_cache),
                "cache_keys": list(self.umc_agent.data_processor.data_cache.keys()),
                "process_rules": self.umc_agent.data_processor.process_rules
            },
            "goal_discoverer": {
                "goal_history_count": len(self.umc_agent.goal_discoverer.goal_history),
                "current_goal": self.umc_agent.goal_discoverer.current_goal,
                "current_goal_basis": self.umc_agent.goal_discoverer.current_goal_basis
            },
            "perf_monitor": {
                "performance_history_count": len(self.umc_agent.perf_monitor.performance_history),
                "error_count": self.umc_agent.perf_monitor.error_count,
                "current_performance_score": self.umc_agent.perf_monitor.current_performance_score
            },
            "feedback_optimizer": {
                "optimize_count": self.umc_agent.feedback_optimizer.optimize_count,
                "feedback_history_count": len(self.umc_agent.feedback_optimizer.feedback_history),
                "current_optimize_result": self.umc_agent.feedback_optimizer.current_optimize_result
            },
            "auto_recovery": {
                "fault_count": len(self.umc_agent.auto_recovery.fault_history),
                "rollback_count": self.umc_agent.auto_recovery.rollback_count,
                "last_backup_time": time.ctime(self.umc_agent.auto_recovery.last_backup_time)
            },
            "strategy_module": {
                "current_strategy_weights": {k: v for k, v in self.umc_agent.strategy_module.param_cfg["STRATEGY"].items()}
            }
        }

        # æ‰“å°çŠ¶æ€ï¼ˆç»“æ„åŒ–ï¼Œä¾¿äºé˜…è¯»ï¼‰
        print("\n=== æ ¸å¿ƒæ¨¡å—çŠ¶æ€æ±‡æ€» ===")
        for module, state in state_summary.items():
            if module == "timestamp":
                print(f"ğŸ“Œ ç›‘æ§æ—¶é—´ï¼š{state}")
                continue
            print(f"\nğŸ“¦ æ¨¡å—ï¼š{module}")
            for k, v in state.items():
                # ç®€åŒ–é•¿æ–‡æœ¬è¾“å‡º
                if isinstance(v, str) and len(v) > 100:
                    v = v[:100] + "..."
                print(f"  - {k}ï¼š{v}")

        # ä¿å­˜çŠ¶æ€æ—¥å¿—
        if save_log:
            log_path = os.path.join(self.debug_log_dir, f"module_state_{time.strftime('%Y%m%d%H%M%S')}.json")
            with open(log_path, "w", encoding="utf-8") as f:
                json.dump(state_summary, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ æ¨¡å—çŠ¶æ€æ—¥å¿—å·²ä¿å­˜ï¼š{log_path}")

        # è®°å½•è°ƒè¯•å†å²
        self.debug_history.append({"type": "module_state", "data": state_summary})
        return state_summary

    def trace_run_step_by_step(self, data: pd.DataFrame, domain_name: str = "unknown") -> Dict[str, Any]:
        """
        ç™½ç›’æ ¸å¿ƒï¼šåˆ†æ­¥è¿½è¸ªUMCæ™ºèƒ½ä½“runæµç¨‹ï¼Œè¾“å‡ºæ¯æ­¥çš„è¾“å…¥/è¾“å‡º/ä¸­é—´å˜é‡
        æ‹†è§£æ­¥éª¤ï¼šç›®æ ‡å‘ç°â†’ç­–ç•¥é€‰æ‹©â†’ä»£è°¢å¾ªç¯â†’æ€§èƒ½æ ¡éªŒâ†’è‡ªä¸»ä¼˜åŒ–
        :param data: æ ‡å‡†åŒ–åçš„æ•°æ®
        :param domain_name: æ•°æ®é¢†åŸŸ
        :return: åˆ†æ­¥è¿½è¸ªç»“æœ
        """
        print("\nğŸš¶ å¼€å§‹åˆ†æ­¥è¿½è¸ªUMCæ™ºèƒ½ä½“è¿è¡Œæµç¨‹...")
        self.step_trace_log = []  # é‡ç½®åˆ†æ­¥æ—¥å¿—
        trace_result = {"domain_name": domain_name, "steps": []}

        try:
            # === æ­¥éª¤1ï¼šè‡ªä¸»å‘ç°ç›®æ ‡ï¼ˆè¾“å‡ºç‰¹å¾é‡è¦æ€§ï¼‰ ===
            print("\n===== æ­¥éª¤1ï¼šè‡ªä¸»ç›®æ ‡å‘ç° =====")
            step1_start = time.time()
            goal_result = self.umc_agent.goal_discoverer.discover_goal(data)
            step1_end = time.time()
            # è®°å½•æ­¥éª¤1è¯¦æƒ…
            step1_data = {
                "step": "goal_discovery",
                "duration": f"{step1_end - step1_start:.3f}s",
                "input_shape": data.shape,
                "output_goal": goal_result["goal"],
                "feature_importance": goal_result["feature_importance"],
                "priority": goal_result["priority"]
            }
            trace_result["steps"].append(step1_data)
            self.step_trace_log.append(step1_data)
            # æ‰“å°æ­¥éª¤1å…³é”®ä¿¡æ¯
            print(f"âœ… ç›®æ ‡å‘ç°è€—æ—¶ï¼š{step1_data['duration']}")
            print(f"ğŸ¯ å‘ç°ç›®æ ‡ï¼š{step1_data['output_goal']}")
            print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§TOP1ï¼š{max(step1_data['feature_importance'].items(), key=lambda x: x[1])}")

            # === æ­¥éª¤2ï¼šé€‰æ‹©æœ€ä¼˜ç­–ç•¥ï¼ˆè¾“å‡ºç­–ç•¥å¾—åˆ†ï¼‰ ===
            print("\n===== æ­¥éª¤2ï¼šæœ€ä¼˜ç­–ç•¥é€‰æ‹© =====")
            step2_start = time.time()
            # å…ˆè¿è¡Œé¢„ä»£è°¢å¾ªç¯è·å–å› å­
            mock_adapt_rules = {"factor_mapping": {"default": "stability"}}
            metabolic_pre = self.umc_agent.metabolic_cycle.run(data, goal_result["goal"], mock_adapt_rules)
            strategy_result = self.umc_agent.strategy_module.select_optimal_strategy(domain_name, metabolic_pre["core_factors"])
            step2_end = time.time()
            # è®°å½•æ­¥éª¤2è¯¦æƒ…
            step2_data = {
                "step": "strategy_selection",
                "duration": f"{step2_end - step2_start:.3f}s",
                "input_factors": metabolic_pre["core_factors"],
                "output_strategy": strategy_result["strategy_name"],
                "strategy_score": strategy_result["strategy_score"],
                "strategy_weights": strategy_result["factor_weight"]
            }
            trace_result["steps"].append(step2_data)
            self.step_trace_log.append(step2_data)
            # æ‰“å°æ­¥éª¤2å…³é”®ä¿¡æ¯
            print(f"âœ… ç­–ç•¥é€‰æ‹©è€—æ—¶ï¼š{step2_data['duration']}")
            print(f"ğŸ“‹ æœ€ä¼˜ç­–ç•¥ï¼š{step2_data['output_strategy']}ï¼ˆå¾—åˆ†ï¼š{step2_data['strategy_score']:.2f}ï¼‰")

            # === æ­¥éª¤3ï¼šè¿è¡Œä»£è°¢å¾ªç¯ï¼ˆè¾“å‡ºæ ¸å¿ƒå› å­/ç¨³å®šæ€§ï¼‰ ===
            print("\n===== æ­¥éª¤3ï¼šä»£è°¢å¾ªç¯æ‰§è¡Œ =====")
            step3_start = time.time()
            metabolic_result = self.umc_agent.metabolic_cycle.run(data, goal_result["goal"], {"factor_mapping": strategy_result["factor_weight"]})
            step3_end = time.time()
            # è®°å½•æ­¥éª¤3è¯¦æƒ…
            step3_data = {
                "step": "metabolic_cycle",
                "duration": f"{step3_end - step3_start:.3f}s",
                "core_factors": metabolic_result["core_factors"],
                "stability_score": metabolic_result["stability_score"],
                "cycle_count": metabolic_result["cycle_count"],
                "is_stable": metabolic_result["is_stable"]
            }
            trace_result["steps"].append(step3_data)
            self.step_trace_log.append(step3_data)
            # æ‰“å°æ­¥éª¤3å…³é”®ä¿¡æ¯
            print(f"âœ… ä»£è°¢å¾ªç¯è€—æ—¶ï¼š{step3_data['duration']}")
            print(f"ğŸ”„ å¾ªç¯æ¬¡æ•°ï¼š{step3_data['cycle_count']} | ç¨³å®šæ€§å¾—åˆ†ï¼š{step3_data['stability_score']:.2f}")
            print(f"ğŸ“Š æ ¸å¿ƒå› å­ï¼š{step3_data['core_factors']}")

            # === æ­¥éª¤4ï¼šæ€§èƒ½æ ¡éªŒï¼ˆè¾“å‡ºå¾—åˆ†/é”™è¯¯è®¡æ•°ï¼‰ ===
            print("\n===== æ­¥éª¤4ï¼šæ€§èƒ½é—­ç¯éªŒè¯ =====")
            step4_start = time.time()
            perf_score = self.umc_agent.perf_monitor.score_result(metabolic_result, goal_result["goal"])
            step4_end = time.time()
            # è®°å½•æ­¥éª¤4è¯¦æƒ…
            step4_data = {
                "step": "performance_validation",
                "duration": f"{step4_end - step4_start:.3f}s",
                "input_stability": metabolic_result["stability_score"],
                "output_score": perf_score,
                "error_count": self.umc_agent.perf_monitor.error_count,
                "is_passed": perf_score >= float(self.umc_agent.perf_monitor.param_cfg["VALIDATION"]["blackbox_test_threshold"])
            }
            trace_result["steps"].append(step4_data)
            self.step_trace_log.append(step4_data)
            # æ‰“å°æ­¥éª¤4å…³é”®ä¿¡æ¯
            print(f"âœ… æ€§èƒ½æ ¡éªŒè€—æ—¶ï¼š{step4_data['duration']}")
            print(f"ğŸ“Š æ€§èƒ½å¾—åˆ†ï¼š{step4_data['output_score']:.2f} | æ˜¯å¦è¾¾æ ‡ï¼š{step4_data['is_passed']}")
            print(f"âŒ é”™è¯¯è®¡æ•°ï¼š{step4_data['error_count']}")

            # === æ­¥éª¤5ï¼šè‡ªä¸»å­¦ä¹ åé¦ˆï¼ˆè¾“å‡ºä¼˜åŒ–ç»“æœï¼‰ ===
            print("\n===== æ­¥éª¤5ï¼šè‡ªä¸»å­¦ä¹ åé¦ˆ =====")
            step5_start = time.time()
            feedback_result = self.umc_agent.feedback_optimizer.feedback_optimize(data, metabolic_result)
            step5_end = time.time()
            # è®°å½•æ­¥éª¤5è¯¦æƒ…
            step5_data = {
                "step": "self_learning_feedback",
                "duration": f"{step5_end - step5_start:.3f}s",
                "input_perf_score": perf_score,
                "optimize_result": feedback_result,
                "optimize_count": self.umc_agent.feedback_optimizer.optimize_count
            }
            trace_result["steps"].append(step5_data)
            self.step_trace_log.append(step5_data)
            # æ‰“å°æ­¥éª¤5å…³é”®ä¿¡æ¯
            print(f"âœ… è‡ªä¸»ä¼˜åŒ–è€—æ—¶ï¼š{step5_data['duration']}")
            if feedback_result["optimize_status"] != "no_optimize":
                print(f"ğŸ”§ ä¼˜åŒ–ç›®æ ‡ï¼š{feedback_result['adjust_target']} | è°ƒæ•´å¹…åº¦ï¼š{feedback_result['adjust_amount']:.3f}")
                print(f"âš–ï¸  æƒé‡å˜åŒ–ï¼š{feedback_result['old_weight']:.2f} â†’ {feedback_result['new_weight']:.2f}")
            else:
                print(f"ğŸ”§ æ— éœ€ä¼˜åŒ–ï¼š{feedback_result['reason']}")

            # === æ±‡æ€»åˆ†æ­¥ç»“æœ ===
            trace_result["total_duration"] = f"{sum([float(step['duration'].replace('s','')) for step in trace_result['steps']]):.3f}s"
            trace_result["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")

            # ä¿å­˜åˆ†æ­¥è¿½è¸ªæ—¥å¿—
            log_path = os.path.join(self.debug_log_dir, f"step_trace_{time.strftime('%Y%m%d%H%M%S')}.json")
            with open(log_path, "w", encoding="utf-8") as f:
                json.dump(trace_result, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ åˆ†æ­¥è¿½è¸ªæ—¥å¿—å·²ä¿å­˜ï¼š{log_path}")
            print(f"\nğŸ åˆ†æ­¥è¿½è¸ªå®Œæˆï¼æ€»è€—æ—¶ï¼š{trace_result['total_duration']}")

            # è®°å½•è°ƒè¯•å†å²
            self.debug_history.append({"type": "step_trace", "data": trace_result})
            return trace_result

        except Exception as e:
            error_msg = f"åˆ†æ­¥è¿½è¸ªå¤±è´¥ï¼š{str(e)}\n{traceback.format_exc()}"
            print(f"\nâŒ {error_msg}")
            # è®°å½•é”™è¯¯æ—¥å¿—
            error_log_path = os.path.join(self.debug_log_dir, f"step_trace_error_{time.strftime('%Y%m%d%H%M%S')}.txt")
            with open(error_log_path, "w", encoding="utf-8") as f:
                f.write(error_msg)
            self.debug_history.append({"type": "step_trace_error", "data": error_msg})
            raise e

    def analyze_param_sensitivity(self, data: pd.DataFrame, param_name: str, param_values: List[float], param_section: str = "AGI_L3") -> Dict[str, Any]:
        """
        ç™½ç›’æ ¸å¿ƒï¼šå‚æ•°æ•æ„Ÿåº¦åˆ†æï¼ˆæµ‹è¯•ä¸åŒå‚æ•°å€¼å¯¹ç»“æœçš„å½±å“ï¼‰
        é€‚ç”¨åœºæ™¯ï¼šè°ƒè¯•ç›®æ ‡å‘ç°é˜ˆå€¼ã€åé¦ˆç‡ã€æ•…éšœé˜ˆå€¼ç­‰å…³é”®å‚æ•°
        :param data: æ ‡å‡†åŒ–åçš„æ•°æ®
        :param param_name: è¦åˆ†æçš„å‚æ•°åï¼ˆå¦‚goal_discovery_thresholdï¼‰
        :param param_values: æµ‹è¯•çš„å‚æ•°å€¼åˆ—è¡¨ï¼ˆå¦‚[0.3,0.4,0.5,0.6,0.7]ï¼‰
        :param param_section: å‚æ•°æ‰€åœ¨çš„é…ç½®æ®µï¼ˆå¦‚AGI_L3/METABOLISMï¼‰
        :return: å‚æ•°æ•æ„Ÿåº¦åˆ†æç»“æœ
        """
        print(f"\nğŸ“Š å¼€å§‹å‚æ•°æ•æ„Ÿåº¦åˆ†æï¼š{param_section}.{param_name}")
        analysis_result = {
            "param_name": param_name,
            "param_section": param_section,
            "param_values": param_values,
            "metrics": ["goal_priority", "stability_score", "perf_score", "optimize_count"],
            "results": [],
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

        # ä¿å­˜åŸå§‹å‚æ•°å€¼ï¼ˆåˆ†æåæ¢å¤ï¼‰
        original_value = self.umc_agent.perf_monitor.param_cfg[param_section][param_name]

        try:
            for value in param_values:
                print(f"\n--- æµ‹è¯•å‚æ•°å€¼ï¼š{value} ---")
                # æ›´æ–°å‚æ•°å€¼
                self.umc_agent.perf_monitor.param_cfg[param_section][param_name] = str(value)
                with open("parameters.ini", "w", encoding="utf-8") as f:
                    self.umc_agent.perf_monitor.param_cfg.write(f)
                
                # é‡æ–°åˆå§‹åŒ–å—å½±å“çš„æ¨¡å—
                self.umc_agent.goal_discoverer = AutonomousGoalDiscovery()
                self.umc_agent.feedback_optimizer = SelfLearningFeedback()
                self.umc_agent.auto_recovery = AutoRecovery()

                # è¿è¡Œæ ¸å¿ƒæµç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                goal_result = self.umc_agent.goal_discoverer.discover_goal(data)
                mock_adapt_rules = {"factor_mapping": {"default": "stability"}}
                metabolic_pre = self.umc_agent.metabolic_cycle.run(data, goal_result["goal"], mock_adapt_rules)
                strategy_result = self.umc_agent.strategy_module.select_optimal_strategy("unknown", metabolic_pre["core_factors"])
                metabolic_result = self.umc_agent.metabolic_cycle.run(data, goal_result["goal"], {"factor_mapping": strategy_result["factor_weight"]})
                perf_score = self.umc_agent.perf_monitor.score_result(metabolic_result, goal_result["goal"])
                feedback_result = self.umc_agent.feedback_optimizer.feedback_optimize(data, metabolic_result)

                # è®°å½•è¯¥å‚æ•°å€¼çš„ç»“æœ
                result_item = {
                    "param_value": value,
                    "goal_priority": goal_result["priority"],
                    "stability_score": metabolic_result["stability_score"],
                    "perf_score": perf_score,
                    "optimize_count": self.umc_agent.feedback_optimizer.optimize_count
                }
                analysis_result["results"].append(result_item)

                # æ‰“å°è¯¥è½®ç»“æœ
                print(f"  ç›®æ ‡ä¼˜å…ˆçº§ï¼š{result_item['goal_priority']}")
                print(f"  ç¨³å®šæ€§å¾—åˆ†ï¼š{result_item['stability_score']:.2f}")
                print(f"  æ€§èƒ½å¾—åˆ†ï¼š{result_item['perf_score']:.2f}")
                print(f"  ä¼˜åŒ–æ¬¡æ•°ï¼š{result_item['optimize_count']}")

            # ç”Ÿæˆæ•æ„Ÿåº¦åˆ†æå›¾è¡¨
            self._plot_param_sensitivity(analysis_result)

            # ä¿å­˜åˆ†æç»“æœ
            log_path = os.path.join(self.debug_log_dir, f"param_sensitivity_{param_name}_{time.strftime('%Y%m%d%H%M%S')}.json")
            with open(log_path, "w", encoding="utf-8") as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ å‚æ•°æ•æ„Ÿåº¦åˆ†ææ—¥å¿—å·²ä¿å­˜ï¼š{log_path}")

            # è®°å½•è°ƒè¯•å†å²
            self.debug_history.append({"type": "param_sensitivity", "data": analysis_result})
            self.param_analysis_result = analysis_result
            return analysis_result

        finally:
            # æ¢å¤åŸå§‹å‚æ•°å€¼
            self.umc_agent.perf_monitor.param_cfg[param_section][param_name] = original_value
            with open("parameters.ini", "w", encoding="utf-8") as f:
                self.umc_agent.perf_monitor.param_cfg.write(f)
            print(f"\nğŸ”™ å·²æ¢å¤åŸå§‹å‚æ•°å€¼ï¼š{original_value}")

    def _plot_param_sensitivity(self, analysis_result: Dict[str, Any]) -> None:
        """ç”Ÿæˆå‚æ•°æ•æ„Ÿåº¦åˆ†æå›¾è¡¨"""
        param_values = analysis_result["param_values"]
        metrics = analysis_result["metrics"]
        results = analysis_result["results"]

        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        axes = axes.flatten()

        for idx, metric in enumerate(metrics):
            # æå–è¯¥æŒ‡æ ‡çš„æ‰€æœ‰å€¼
            metric_values = [item[metric] for item in results]
            # ç»˜åˆ¶æŠ˜çº¿å›¾
            axes[idx].plot(param_values, metric_values, marker="o", linewidth=2, markersize=6)
            axes[idx].set_title(f"{metric} éš {analysis_result['param_name']} å˜åŒ–", fontsize=10, fontweight="bold")
            axes[idx].set_xlabel(analysis_result['param_name'])
            axes[idx].set_ylabel(metric)
            axes[idx].grid(True, alpha=0.3)
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for x, y in zip(param_values, metric_values):
                axes[idx].text(x, y, f"{y:.2f}", ha="center", va="bottom", fontsize=8)

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        fig_path = os.path.join(self.debug_log_dir, f"param_sensitivity_{analysis_result['param_name']}_{time.strftime('%Y%m%d%H%M%S')}.png")
        plt.savefig(fig_path, dpi=300, bbox_inches="tight")
        print(f"ğŸ“¸ å‚æ•°æ•æ„Ÿåº¦å›¾è¡¨å·²ä¿å­˜ï¼š{fig_path}")
        plt.show()

    def debug_core_function(self, func: Callable, func_name: str, *args, **kwargs) -> Dict[str, Any]:
        """
        ç™½ç›’æ ¸å¿ƒï¼šå•æ­¥è°ƒè¯•æ ¸å¿ƒå‡½æ•°ï¼Œè¾“å‡ºè¾“å…¥/è¾“å‡º/æ‰§è¡Œæ—¶é—´/å¼‚å¸¸
        :param func: è¦è°ƒè¯•çš„æ ¸å¿ƒå‡½æ•°ï¼ˆå¦‚data_processor._handle_missing_valuesï¼‰
        :param func_name: å‡½æ•°åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        :param args/kwargs: å‡½æ•°å‚æ•°
        :return: è°ƒè¯•ç»“æœ
        """
        print(f"\nğŸ”§ å¼€å§‹å•æ­¥è°ƒè¯•å‡½æ•°ï¼š{func_name}")
        debug_result = {
            "func_name": func_name,
            "input_args": str(args)[:200] + "..." if len(str(args)) > 200 else str(args),
            "input_kwargs": str(kwargs)[:200] + "..." if len(str(kwargs)) > 200 else str(kwargs),
            "start_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "duration": 0.0,
            "output": None,
            "error": None
        }

        try:
            # æ‰§è¡Œå‡½æ•°å¹¶è®¡æ—¶
            start = time.time()
            output = func(*args, **kwargs)
            end = time.time()

            # è®°å½•æˆåŠŸç»“æœ
            debug_result["duration"] = f"{end - start:.3f}s"
            debug_result["output"] = str(output)[:500] + "..." if len(str(output)) > 500 else str(output)
            print(f"âœ… å‡½æ•°æ‰§è¡ŒæˆåŠŸï¼è€—æ—¶ï¼š{debug_result['duration']}")
            print(f"ğŸ“¤ å‡½æ•°è¾“å‡ºï¼š{debug_result['output']}")

        except Exception as e:
            # è®°å½•å¼‚å¸¸ç»“æœ
            error_msg = f"{str(e)}\n{traceback.format_exc()}"
            debug_result["error"] = error_msg[:1000] + "..." if len(error_msg) > 1000 else error_msg
            print(f"âŒ å‡½æ•°æ‰§è¡Œå¼‚å¸¸ï¼š{debug_result['error']}")

        # ä¿å­˜å‡½æ•°è°ƒè¯•æ—¥å¿—
        log_path = os.path.join(self.debug_log_dir, f"func_debug_{func_name}_{time.strftime('%Y%m%d%H%M%S')}.json")
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(debug_result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å‡½æ•°è°ƒè¯•æ—¥å¿—å·²ä¿å­˜ï¼š{log_path}")

        # è®°å½•è°ƒè¯•å†å²
        self.debug_history.append({"type": "func_debug", "data": debug_result})
        return debug_result

    def compare_config(self, config_path1: str = "./parameters.ini", config_path2: str = "./parameters_default.ini") -> Dict[str, Any]:
        """
        ç™½ç›’è¾…åŠ©ï¼šå¯¹æ¯”ä¸¤ä¸ªé…ç½®æ–‡ä»¶çš„å·®å¼‚ï¼Œå®šä½å‚æ•°é—®é¢˜
        :param config_path1: å½“å‰é…ç½®æ–‡ä»¶
        :param config_path2: å‚è€ƒé…ç½®æ–‡ä»¶ï¼ˆå¦‚é»˜è®¤é…ç½®ï¼‰
        :return: é…ç½®å·®å¼‚ç»“æœ
        """
        print(f"\nğŸ” å¯¹æ¯”é…ç½®æ–‡ä»¶ï¼š{config_path1} vs {config_path2}")
        # åŠ è½½ä¸¤ä¸ªé…ç½®æ–‡ä»¶
        cfg1 = configparser.ConfigParser()
        cfg1.read(config_path1, encoding="utf-8")
        cfg2 = configparser.ConfigParser()
        cfg2.read(config_path2, encoding="utf-8") if os.path.exists(config_path2) else None

        compare_result = {
            "only_in_cfg1": [],  # ä»…åœ¨cfg1ä¸­å­˜åœ¨çš„é…ç½®
            "only_in_cfg2": [],  # ä»…åœ¨cfg2ä¸­å­˜åœ¨çš„é…ç½®
            "value_diff": [],    # é”®ç›¸åŒä½†å€¼ä¸åŒçš„é…ç½®
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

        # éå†cfg1çš„æ‰€æœ‰é…ç½®
        for section in cfg1.sections():
            for key, value in cfg1[section].items():
                full_key = f"{section}.{key}"
                # æ£€æŸ¥cfg2ä¸­æ˜¯å¦å­˜åœ¨è¯¥é…ç½®
                if not cfg2.has_section(section) or not cfg2[section].get(key):
                    compare_result["only_in_cfg1"].append(full_key)
                else:
                    # å¯¹æ¯”å€¼æ˜¯å¦ä¸åŒ
                    if value != cfg2[section][key]:
                        compare_result["value_diff"].append({
                            "key": full_key,
                            "cfg1_value": value,
                            "cfg2_value": cfg2[section][key]
                        })

        # éå†cfg2çš„æ‰€æœ‰é…ç½®ï¼ˆæ£€æŸ¥ä»…åœ¨cfg2ä¸­å­˜åœ¨çš„ï¼‰
        if os.path.exists(config_path2):
            for section in cfg2.sections():
                for key, value in cfg2[section].items():
                    full_key = f"{section}.{key}"
                    if not cfg1.has_section(section) or not cfg1[section].get(key):
                        compare_result["only_in_cfg2"].append(full_key)

        # æ‰“å°å¯¹æ¯”ç»“æœ
        print("\n=== é…ç½®å¯¹æ¯”ç»“æœ ===")
        if compare_result["only_in_cfg1"]:
            print(f"ğŸ“Œ ä»…åœ¨å½“å‰é…ç½®ä¸­å­˜åœ¨ï¼š{compare_result['only_in_cfg1']}")
        if compare_result["only_in_cfg2"]:
            print(f"ğŸ“Œ ä»…åœ¨å‚è€ƒé…ç½®ä¸­å­˜åœ¨ï¼š{compare_result['only_in_cfg2']}")
        if compare_result["value_diff"]:
            print(f"\nğŸ“Œ å€¼ä¸åŒçš„é…ç½®ï¼š")
            for diff in compare_result["value_diff"]:
                print(f"  - {diff['key']}ï¼š{diff['cfg1_value']} (å½“å‰) vs {diff['cfg2_value']} (å‚è€ƒ)")
        if not any([compare_result["only_in_cfg1"], compare_result["only_in_cfg2"], compare_result["value_diff"]]):
            print(f"âœ… ä¸¤ä¸ªé…ç½®æ–‡ä»¶å®Œå…¨ä¸€è‡´")

        # ä¿å­˜å¯¹æ¯”æ—¥å¿—
        log_path = os.path.join(self.debug_log_dir, f"config_compare_{time.strftime('%Y%m%d%H%M%S')}.json")
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(compare_result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ é…ç½®å¯¹æ¯”æ—¥å¿—å·²ä¿å­˜ï¼š{log_path}")

        # è®°å½•è°ƒè¯•å†å²
        self.debug_history.append({"type": "config_compare", "data": compare_result})
        return compare_result

# ç™½ç›’è°ƒè¯•å·¥å…·éªŒè¯å…¥å£ï¼ˆä¸€ç«™å¼æµ‹è¯•æ‰€æœ‰ç™½ç›’åŠŸèƒ½ï¼‰
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–åŸºç¡€UMCæ™ºèƒ½ä½“
    print("ğŸš€ åˆå§‹åŒ–UMCæ™ºèƒ½ä½“ï¼ˆåŸºç¡€ï¼‰...")
    umc_agent = UMCAgent()
    # ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    default_config_path = "./parameters_default.ini"
    if not os.path.exists(default_config_path):
        umc_agent._init_default_config("./")
        os.rename("./parameters.ini", default_config_path)
        umc_agent = UMCAgent()  # é‡æ–°åˆå§‹åŒ–ï¼Œç”Ÿæˆå½“å‰é…ç½®

    # 2. åˆ›å»ºæµ‹è¯•æ•°æ®å¹¶åŠ è½½
    print("\nğŸ“„ ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    test_data = create_test_data(domain_name="quantum", sample_count=100)
    standardized_data = umc_agent.load_data("./test_data_quantum.csv", domain_name="quantum")

    # 3. åˆå§‹åŒ–ç™½ç›’è°ƒè¯•å™¨
    print("\nğŸ”§ åˆå§‹åŒ–ç™½ç›’è°ƒè¯•å™¨...")
    whitebox = WhiteboxDebugger(umc_agent)

    # 4. åŠŸèƒ½1ï¼šç›‘æ§æ¨¡å—å†…éƒ¨çŠ¶æ€
    whitebox.monitor_module_states()

    # 5. åŠŸèƒ½2ï¼šåˆ†æ­¥è¿½è¸ªè¿è¡Œæµç¨‹
    trace_result = whitebox.trace_run_step_by_step(standardized_data, domain_name="quantum")

    # 6. åŠŸèƒ½3ï¼šå‚æ•°æ•æ„Ÿåº¦åˆ†æï¼ˆæµ‹è¯•ç›®æ ‡å‘ç°é˜ˆå€¼ï¼‰
    analysis_result = whitebox.analyze_param_sensitivity(
        standardized_data,
        param_name="goal_discovery_threshold",
        param_values=[0.3, 0.4, 0.5, 0.6, 0.7],
        param_section="AGI_L3"
    )

    # 7. åŠŸèƒ½4ï¼šå•æ­¥è°ƒè¯•æ ¸å¿ƒå‡½æ•°ï¼ˆæµ‹è¯•ç¼ºå¤±å€¼å¤„ç†ï¼‰
    debug_result = whitebox.debug_core_function(
        func=umc_agent.data_processor._handle_missing_values,
        func_name="data_processor._handle_missing_values",
        data=standardized_data.copy()
    )

    # 8. åŠŸèƒ½5ï¼šé…ç½®æ–‡ä»¶å¯¹æ¯”
    whitebox.compare_config(config_path1="./parameters.ini", config_path2="./parameters_default.ini")

    # 9. æŸ¥çœ‹è°ƒè¯•å†å²
    print("\n=== ç™½ç›’è°ƒè¯•å†å²æ±‡æ€» ===")
    print(f"è°ƒè¯•è®°å½•æ•°ï¼š{len(whitebox.debug_history)}")
    for idx, record in enumerate(whitebox.debug_history):
        print(f"  {idx+1}. ç±»å‹ï¼š{record['type']}")

    print("\nğŸ‰ ç™½ç›’è°ƒè¯•å·¥å…·æµ‹è¯•å®Œæˆï¼æ‰€æœ‰æ—¥å¿—å·²ä¿å­˜è‡³ ./whitebox_logs")