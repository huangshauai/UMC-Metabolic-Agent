# -*- coding: utf-8 -*-
"""
UMC-Metabolic-Agent å·¥å…·å°è£…ä¸æ„å»ºæ¨¡å—ï¼ˆä¸€ç«™å¼ä½¿ç”¨å…¥å£ï¼‰
æ ¸å¿ƒé€»è¾‘ï¼šæ•´åˆæ‰€æœ‰æ ¸å¿ƒæ¨¡å—ï¼Œæä¾›ç®€æ´APIï¼Œæ”¯æŒä¸€é”®è¿è¡Œ/æ•°æ®å¤„ç†/ç»“æœå¯è§†åŒ–
è®¾è®¡åŸåˆ™ï¼šæ˜“ç”¨æ€§ä¼˜å…ˆã€é…ç½®è‡ªåŠ¨åŒ–ã€ç»“æœå¯è§£é‡Šï¼Œé€‚é…æ–°æ‰‹å¿«é€Ÿä¸Šæ‰‹
"""
import configparser
import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, Any, Optional, List
import warnings
warnings.filterwarnings("ignore")
plt.rcParams["font.sans-serif"] = ["SimHei"]  # æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams["axes.unicode_minus"] = False

# å¯¼å…¥æ‰€æœ‰æ ¸å¿ƒæ¨¡å—
from data_processing import DataProcessor
from goal_discovery import AutonomousGoalDiscovery
from umc_metabolism import MetabolicCycle
from umc_strategy import UMCStrategy
from umc_performance import PerformanceMonitor
from self_learning_feedback import SelfLearningFeedback
from auto_recovery import AutoRecovery
from signal_interpreter import SignalInterpreter

class UMCAgent:
    """UMCæ™ºèƒ½ä½“å·¥å…·ç±»ï¼ˆä¸€ç«™å¼æ ¸å¿ƒåŠŸèƒ½å°è£…ï¼‰"""
    def __init__(self, config_dir: str = "./"):
        """
        åˆå§‹åŒ–UMCæ™ºèƒ½ä½“
        :param config_dir: é…ç½®æ–‡ä»¶ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰
        """
        # 1. è‡ªåŠ¨åˆå§‹åŒ–é…ç½®æ–‡ä»¶ï¼ˆæ— é…ç½®æ—¶ç”Ÿæˆé»˜è®¤é…ç½®ï¼‰
        self._init_default_config(config_dir)
        # 2. åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—
        self.data_processor = DataProcessor()
        self.goal_discoverer = AutonomousGoalDiscovery()
        self.metabolic_cycle = MetabolicCycle()
        self.strategy_module = UMCStrategy()
        self.perf_monitor = PerformanceMonitor()
        self.feedback_optimizer = SelfLearningFeedback()
        self.auto_recovery = AutoRecovery()
        self.signal_interpreter = SignalInterpreter()
        # 3. åˆå§‹åŒ–è¿è¡ŒçŠ¶æ€
        self.run_history = []
        self.current_summary = None

    def _init_default_config(self, config_dir: str) -> None:
        """è‡ªåŠ¨ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶ï¼ˆparameters.ini/paths.iniï¼‰"""
        # === ç”Ÿæˆparameters.ini ===
        param_path = os.path.join(config_dir, "parameters.ini")
        if not os.path.exists(param_path):
            param_cfg = configparser.ConfigParser()
            # BASICæ®µ
            param_cfg["BASIC"] = {
                "runtime_log_level": "DEBUG",
                "cycle_speed": "0.1",
                "data_cache_size": "100"
            }
            # METABOLISMæ®µ
            param_cfg["METABOLISM"] = {
                "core_factor_weight": "0.8",
                "energy_consumption_limit": "0.9",
                "stability_threshold": "0.8"
            }
            # STRATEGYæ®µ
            param_cfg["STRATEGY"] = {
                "qubit_stability": "0.8",
                "atomic_frequency": "0.7",
                "logistics_efficiency": "0.75",
                "unknown_domain": "0.6"
            }
            # VALIDATIONæ®µ
            param_cfg["VALIDATION"] = {
                "blackbox_test_threshold": "0.7"
            }
            # AGI_L3æ®µ
            param_cfg["AGI_L3"] = {
                "goal_discovery_threshold": "0.5",
                "self_learning_feedback_rate": "0.5",
                "auto_recovery_fault_threshold": "3"
            }
            # å†™å…¥é…ç½®æ–‡ä»¶
            with open(param_path, "w", encoding="utf-8") as f:
                param_cfg.write(f)
        
        # === ç”Ÿæˆpaths.ini ===
        path_path = os.path.join(config_dir, "paths.ini")
        if not os.path.exists(path_path):
            path_cfg = configparser.ConfigParser()
            path_cfg["PATH"] = {
                "log_dir": "./logs",
                "backup_dir": "./backups",
                "processed_data_dir": "./processed_data",
                "result_dir": "./results"
            }
            # å†™å…¥é…ç½®æ–‡ä»¶
            with open(path_path, "w", encoding="utf-8") as f:
                path_cfg.write(f)
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        path_cfg = configparser.ConfigParser()
        path_cfg.read(path_path, encoding="utf-8")
        for dir_name in path_cfg["PATH"].values():
            os.makedirs(dir_name, exist_ok=True)

    def load_data(self, data_path: str, domain_name: str = "unknown") -> pd.DataFrame:
        """
        å·¥å…·å‡½æ•°ï¼šåŠ è½½å¹¶æ ‡å‡†åŒ–æ•°æ®ï¼ˆæ”¯æŒCSV/Excelï¼‰
        :param data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆ.csv/.xlsxï¼‰
        :param domain_name: æ•°æ®é¢†åŸŸåç§°
        :return: æ ‡å‡†åŒ–åçš„æ•°æ®
        """
        # 1. åŠ è½½åŸå§‹æ•°æ®
        if data_path.endswith(".csv"):
            raw_data = pd.read_csv(data_path, encoding="utf-8")
        elif data_path.endswith(".xlsx"):
            raw_data = pd.read_excel(data_path)
        else:
            raise ValueError("ä»…æ”¯æŒCSV/Excelæ ¼å¼æ•°æ®")
        
        # 2. æ ‡å‡†åŒ–æ•°æ®ï¼ˆå¸¦æ•…éšœæ¢å¤ï¼‰
        def _process_data():
            return self.data_processor.standardize_data(raw_data, domain_name)
        
        standardized_data = self.auto_recovery.run_with_recovery(_process_data)
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼š{data_path} | å½¢çŠ¶ï¼š{standardized_data.shape} | é¢†åŸŸï¼š{domain_name}")
        return standardized_data

    def run(self, data: pd.DataFrame, domain_name: str = "unknown") -> Dict[str, Any]:
        """
        æ ¸å¿ƒå·¥å…·ï¼šä¸€é”®è¿è¡ŒUMCæ™ºèƒ½ä½“å…¨æµç¨‹
        :param data: æ ‡å‡†åŒ–åçš„æ•°æ®
        :param domain_name: æ•°æ®é¢†åŸŸåç§°
        :return: å…¨æµç¨‹è¿è¡Œç»“æœï¼ˆå«ç›®æ ‡/ç­–ç•¥/ä»£è°¢/æ€§èƒ½/ä¼˜åŒ–ï¼‰
        """
        # åŒ…è£…æ ¸å¿ƒè¿è¡Œé€»è¾‘ï¼ˆå¸¦æ•…éšœæ¢å¤ï¼‰
        def _core_run_logic():
            # 1. è‡ªä¸»å‘ç°ç›®æ ‡
            goal_result = self.goal_discoverer.discover_goal(data)
            print(f"ğŸ¯ è‡ªä¸»å‘ç°ç›®æ ‡ï¼š{goal_result['goal']} | ä¼˜å…ˆçº§ï¼š{goal_result['priority']}")
            
            # 2. é€‰æ‹©æœ€ä¼˜ç­–ç•¥
            # å…ˆè¿è¡Œä¸€æ¬¡ä»£è°¢å¾ªç¯è·å–å› å­
            mock_adapt_rules = {"factor_mapping": {"default": "stability"}}
            metabolic_pre = self.metabolic_cycle.run(data, goal_result["goal"], mock_adapt_rules)
            strategy_result = self.strategy_module.select_optimal_strategy(domain_name, metabolic_pre["core_factors"])
            print(f"ğŸ“‹ æœ€ä¼˜ç­–ç•¥ï¼š{strategy_result['strategy_name']} | å¾—åˆ†ï¼š{strategy_result['strategy_score']:.2f}")
            
            # 3. æ­£å¼è¿è¡Œä»£è°¢å¾ªç¯
            metabolic_result = self.metabolic_cycle.run(data, goal_result["goal"], {"factor_mapping": strategy_result["factor_weight"]})
            print(f"ğŸ”„ ä»£è°¢å¾ªç¯å®Œæˆï¼šç¨³å®šå¾—åˆ†{metabolic_result['stability_score']:.2f} | å¾ªç¯æ¬¡æ•°{metabolic_result['cycle_count']}")
            
            # 4. æ€§èƒ½æ ¡éªŒ
            perf_score = self.perf_monitor.score_result(metabolic_result, goal_result["goal"])
            print(f"ğŸ“Š æ€§èƒ½æ ¡éªŒå¾—åˆ†ï¼š{perf_score:.2f}")
            
            # 5. è‡ªä¸»å­¦ä¹ åé¦ˆä¼˜åŒ–
            feedback_result = self.feedback_optimizer.feedback_optimize(data, metabolic_result)
            if feedback_result["optimize_status"] != "no_optimize":
                print(f"ğŸ”§ è‡ªä¸»ä¼˜åŒ–å®Œæˆï¼šè°ƒæ•´{feedback_result['adjust_target']}æƒé‡{feedback_result['adjust_amount']:.3f}")
            else:
                print(f"ğŸ”§ æ— éœ€ä¼˜åŒ–ï¼š{feedback_result['reason']}")
            
            # 6. æ„é€ è¿è¡Œç»“æœ
            run_result = {
                "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
                "domain_name": domain_name,
                "data_shape": data.shape,
                "goal_result": goal_result,
                "strategy_result": strategy_result,
                "metabolic_result": metabolic_result,
                "perf_score": perf_score,
                "feedback_result": feedback_result
            }
            
            # 7. ä¿å­˜è¿è¡Œç»“æœ
            self.run_history.append(run_result)
            result_dir = "./results"
            result_path = os.path.join(result_dir, f"run_result_{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}.json")
            with open(result_path, "w", encoding="utf-8") as f:
                json.dump(run_result, f, ensure_ascii=False, indent=2)
            
            # 8. æ›´æ–°å½“å‰æ‘˜è¦
            self.current_summary = self.get_summary(run_result)
            return run_result
        
        # æ‰§è¡Œæ ¸å¿ƒé€»è¾‘ï¼ˆå¸¦æ•…éšœæ¢å¤ï¼‰
        run_result = self.auto_recovery.run_with_recovery(_core_run_logic)
        print(f"âœ… UMCæ™ºèƒ½ä½“è¿è¡Œå®Œæˆï¼")
        return run_result

    def get_summary(self, run_result: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        å·¥å…·å‡½æ•°ï¼šç”Ÿæˆè¿è¡Œç»“æœæ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆï¼Œä¾¿äºæŸ¥çœ‹æ ¸å¿ƒä¿¡æ¯ï¼‰
        :param run_result: è¿è¡Œç»“æœï¼ˆé»˜è®¤å–æœ€æ–°ï¼‰
        :return: ç»“æœæ‘˜è¦
        """
        if run_result is None:
            if not self.run_history:
                return {"message": "æš‚æ— è¿è¡Œè®°å½•"}
            run_result = self.run_history[-1]
        
        summary = {
            "è¿è¡Œæ—¶é—´": run_result["timestamp"],
            "æ•°æ®é¢†åŸŸ": run_result["domain_name"],
            "æ•°æ®è§„æ¨¡": f"{run_result['data_shape'][0]}è¡Œ Ã— {run_result['data_shape'][1]}åˆ—",
            "ä¼˜åŒ–ç›®æ ‡": run_result["goal_result"]["goal"],
            "æœ€ä¼˜ç­–ç•¥": run_result["strategy_result"]["strategy_name"],
            "ä»£è°¢ç¨³å®šæ€§": f"{run_result['metabolic_result']['stability_score']:.2f}",
            "æ€§èƒ½å¾—åˆ†": f"{run_result['perf_score']:.2f}",
            "ä¼˜åŒ–çŠ¶æ€": run_result["feedback_result"]["optimize_status"]
        }
        return summary

    def visualize_result(self, run_result: Optional[Dict[str, Any]] = None, save_fig: bool = True) -> None:
        """
        å·¥å…·å‡½æ•°ï¼šå¯è§†åŒ–è¿è¡Œç»“æœï¼ˆæ ¸å¿ƒå› å­åˆ†å¸ƒ+æ€§èƒ½å¾—åˆ†ï¼‰
        :param run_result: è¿è¡Œç»“æœï¼ˆé»˜è®¤å–æœ€æ–°ï¼‰
        :param save_fig: æ˜¯å¦ä¿å­˜å›¾ç‰‡
        """
        if run_result is None:
            if not self.run_history:
                raise ValueError("æš‚æ— è¿è¡Œè®°å½•ï¼Œæ— æ³•å¯è§†åŒ–")
            run_result = self.run_history[-1]
        
        # åˆ›å»º2Ã—1å­å›¾
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
        
        # å­å›¾1ï¼šä»£è°¢æ ¸å¿ƒå› å­åˆ†å¸ƒ
        factors = run_result["metabolic_result"]["core_factors"]
        ax1.bar(factors.keys(), factors.values(), color=["#1f77b4", "#ff7f0e", "#2ca02c"])
        ax1.set_title(f"ä»£è°¢æ ¸å¿ƒå› å­åˆ†å¸ƒ | é¢†åŸŸï¼š{run_result['domain_name']}", fontsize=12, fontweight="bold")
        ax1.set_ylabel("å› å­å¾—åˆ†ï¼ˆ0~1ï¼‰")
        ax1.set_ylim(0, 1)
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for k, v in factors.items():
            ax1.text(k, v + 0.02, f"{v:.2f}", ha="center", va="bottom")
        
        # å­å›¾2ï¼šå…³é”®æŒ‡æ ‡æ±‡æ€»
        metrics = {
            "æ€§èƒ½å¾—åˆ†": run_result["perf_score"],
            "ä»£è°¢ç¨³å®šæ€§": run_result["metabolic_result"]["stability_score"],
            "ç­–ç•¥å¾—åˆ†": run_result["strategy_result"]["strategy_score"]
        }
        ax2.bar(metrics.keys(), metrics.values(), color=["#d62728", "#9467bd", "#8c564b"])
        ax2.set_title("å…³é”®æŒ‡æ ‡å¾—åˆ†", fontsize=12, fontweight="bold")
        ax2.set_ylabel("å¾—åˆ†ï¼ˆ0~1ï¼‰")
        ax2.set_ylim(0, 1)
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for k, v in metrics.items():
            ax2.text(k, v + 0.02, f"{v:.2f}", ha="center", va="bottom")
        
        # æ•´ä½“å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        if save_fig:
            fig_path = os.path.join("./results", f"visual_result_{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}.png")
            plt.savefig(fig_path, dpi=300, bbox_inches="tight")
            print(f"ğŸ“¸ å¯è§†åŒ–ç»“æœå·²ä¿å­˜ï¼š{fig_path}")
        
        # æ˜¾ç¤ºå›¾ç‰‡
        plt.show()

# å·¥å…·å‡½æ•°ï¼šå¿«é€Ÿåˆ›å»ºæµ‹è¯•æ•°æ®
def create_test_data(domain_name: str = "quantum", sample_count: int = 100) -> pd.DataFrame:
    """
    å¿«é€Ÿåˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆé€‚é…ä¸åŒé¢†åŸŸï¼‰
    :param domain_name: é¢†åŸŸåç§°ï¼ˆquantum/atomic/logisticsï¼‰
    :param sample_count: æ ·æœ¬æ•°é‡
    :return: æµ‹è¯•æ•°æ®
    """
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°
    if domain_name == "quantum":
        data = pd.DataFrame({
            "qubit_stability": np.random.rand(sample_count) * 0.9,
            "energy_consumption": np.random.rand(sample_count) * 0.8,
            "matter_output": np.random.rand(sample_count) * 0.7
        })
    elif domain_name == "atomic":
        data = pd.DataFrame({
            "atomic_frequency": np.random.rand(sample_count) * 0.9,
            "energy_efficiency": np.random.rand(sample_count) * 0.8,
            "particle_yield": np.random.rand(sample_count) * 0.7
        })
    elif domain_name == "logistics":
        data = pd.DataFrame({
            "logistics_efficiency": np.random.rand(sample_count) * 0.9,
            "transport_cost": np.random.rand(sample_count) * 0.8,
            "delivery_speed": np.random.rand(sample_count) * 0.7
        })
    else:
        data = pd.DataFrame({
            "feature_1": np.random.rand(sample_count) * 0.9,
            "feature_2": np.random.rand(sample_count) * 0.8,
            "feature_3": np.random.rand(sample_count) * 0.7
        })
    
    # äººä¸ºæ·»åŠ å°‘é‡ç¼ºå¤±å€¼ï¼ˆæ¨¡æ‹ŸçœŸå®æ•°æ®ï¼‰
    for col in data.columns:
        data.loc[np.random.choice(sample_count, size=int(sample_count*0.05)), col] = np.nan
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    data_path = f"./test_data_{domain_name}.csv"
    data.to_csv(data_path, index=False, encoding="utf-8")
    print(f"ğŸ“„ æµ‹è¯•æ•°æ®å·²ç”Ÿæˆï¼š{data_path}")
    return data

# éªŒè¯å…¥å£ï¼ˆä¸€ç«™å¼æµ‹è¯•UMCæ™ºèƒ½ä½“ï¼‰
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–UMCæ™ºèƒ½ä½“ï¼ˆè‡ªåŠ¨ç”Ÿæˆé…ç½®ï¼‰
    umc_agent = UMCAgent()
    print("ğŸš€ UMCæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆï¼")

    # 2. åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆé‡å­é¢†åŸŸï¼‰
    test_data = create_test_data(domain_name="quantum", sample_count=200)

    # 3. åŠ è½½å¹¶æ ‡å‡†åŒ–æ•°æ®ï¼ˆå°è£…æ•…éšœæ¢å¤ï¼‰
    standardized_data = umc_agent.load_data("./test_data_quantum.csv", domain_name="quantum")

    # 4. ä¸€é”®è¿è¡Œå…¨æµç¨‹
    run_result = umc_agent.run(standardized_data, domain_name="quantum")

    # 5. æŸ¥çœ‹è¿è¡Œç»“æœæ‘˜è¦
    print("\n=== è¿è¡Œç»“æœæ‘˜è¦ ===")
    summary = umc_agent.get_summary(run_result)
    for k, v in summary.items():
        print(f"{k}ï¼š{v}")

    # 6. å¯è§†åŒ–è¿è¡Œç»“æœ
    umc_agent.visualize_result(run_result)

    # 7. æŸ¥çœ‹æ•…éšœ/ä¼˜åŒ–å†å²
    print("\n=== æ•…éšœæ‘˜è¦ ===")
    print(umc_agent.auto_recovery.get_fault_summary())
    print("\n=== ä¼˜åŒ–å†å² ===")
    print(umc_agent.feedback_optimizer.get_feedback_history())