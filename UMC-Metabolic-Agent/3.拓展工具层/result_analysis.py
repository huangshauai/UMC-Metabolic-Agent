# -*- coding: utf-8 -*-
"""
UMC-Metabolic-Agent ç»“æœåˆ†ææ¨¡å—ï¼ˆç»Ÿè®¡åˆ†æ+ç‰¹å¾è¯„ä¼°+é¢†åŸŸé€‚é…+å¼‚å¸¸æ£€æµ‹+æŠ¥å‘Šç”Ÿæˆï¼‰
æ ¸å¿ƒé€»è¾‘ï¼šå¯¹æ™ºèƒ½ä½“è¿è¡Œç»“æœ/è‡ªé€‚åº”æ•ˆæœ/å¤šæ¨¡æ€æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¾“å‡ºå¯è§£é‡Šçš„åˆ†ææŠ¥å‘Š
è®¾è®¡åŸåˆ™ï¼šè‡ªåŠ¨åŒ–ã€å¯è§£é‡Šã€é‡åŒ–è¯„ä¼°ã€é›¶é…ç½®ä½¿ç”¨ï¼Œé€‚é…æ–°æ‰‹åˆ†æå¤šåœºæ™¯ç»“æœæ•°æ®
"""
import pandas as pd
import numpy as np
import scipy.stats as stats
import json
import os
import time
import warnings
from typing import Dict, Any, List, Optional, Union, Tuple
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")
# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from plot_generator import PlotGenerator
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ°plot_generatoræ¨¡å—ï¼Œå¯è§†åŒ–åŠŸèƒ½å°†ä¸å¯ç”¨")
    PlotGenerator = None

class ResultAnalyzer:
    """ç»“æœåˆ†æå™¨ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šç»Ÿè®¡åˆ†æã€ç‰¹å¾è¯„ä¼°ã€é¢†åŸŸé€‚é…åˆ†æã€å¼‚å¸¸æ£€æµ‹ã€æŠ¥å‘Šç”Ÿæˆï¼‰"""
    def __init__(self, output_dir: str = "./analysis_reports"):
        """
        åˆå§‹åŒ–ç»“æœåˆ†æå™¨
        :param output_dir: åˆ†ææŠ¥å‘Šä¿å­˜ç›®å½•
        """
        # åŸºç¡€é…ç½®
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        # åˆå§‹åŒ–å¯è§†åŒ–ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰
        self.plotter = PlotGenerator(output_dir="./analysis_plots") if PlotGenerator else None
        # åˆ†æå†å²
        self.analysis_history = []

    def basic_statistical_analysis(self, data: pd.DataFrame, **kwargs) -> Dict[str, Any]:
        """
        åŸºç¡€ç»Ÿè®¡åˆ†æï¼ˆæ ¸å¿ƒï¼šæè¿°æ€§ç»Ÿè®¡ã€åˆ†å¸ƒæ£€éªŒã€ç›¸å…³æ€§åˆ†æï¼‰
        :param data: å¾…åˆ†ææ•°æ®
        :param kwargs: å¯é€‰å‚æ•°ï¼ˆtarget_colsï¼šç›®æ ‡åˆ—åˆ—è¡¨ï¼Œsave_nameï¼šä¿å­˜åï¼‰
        :return: ç»Ÿè®¡åˆ†æç»“æœ
        """
        print("\nğŸ“Š å¼€å§‹åŸºç¡€ç»Ÿè®¡åˆ†æ...")
        # è§£æå‚æ•°
        target_cols = kwargs.get("target_cols", data.select_dtypes(include=[np.number]).columns.tolist())
        save_name = kwargs.get("save_name", f"basic_stats_{time.strftime('%Y%m%d%H%M%S')}")
        # åªä¿ç•™æ•°å€¼åˆ—
        numeric_data = data[target_cols].copy()

        # 1. æè¿°æ€§ç»Ÿè®¡
        desc_stats = numeric_data.describe().to_dict()
        # è¡¥å……ä¸­ä½æ•°ã€ä¼—æ•°ã€ååº¦ã€å³°åº¦
        extended_stats = {}
        for col in target_cols:
            extended_stats[col] = {
                "median": float(numeric_data[col].median()),
                "mode": float(numeric_data[col].mode().iloc[0] if not numeric_data[col].mode().empty else np.nan),
                "skewness": float(numeric_data[col].skew()),
                "kurtosis": float(numeric_data[col].kurt()),
                "missing_rate": float(numeric_data[col].isnull().sum() / len(numeric_data)),
                "cv": float(numeric_data[col].std() / numeric_data[col].mean()) if numeric_data[col].mean() != 0 else 0.0  # å˜å¼‚ç³»æ•°
            }

        # 2. åˆ†å¸ƒæ­£æ€æ€§æ£€éªŒï¼ˆShapiro-Wilkï¼‰
        normality_test = {}
        for col in target_cols:
            if len(numeric_data[col].dropna()) >= 3:  # è‡³å°‘3ä¸ªæ ·æœ¬
                stat, p_value = stats.shapiro(numeric_data[col].dropna())
                normality_test[col] = {
                    "statistic": float(stat),
                    "p_value": float(p_value),
                    "is_normal": p_value > 0.05  # Î±=0.05
                }
            else:
                normality_test[col] = {"error": "æ ·æœ¬æ•°ä¸è¶³ï¼Œæ— æ³•æ£€éªŒ"}

        # 3. ç›¸å…³æ€§åˆ†æï¼ˆPearson/Spearmanï¼‰
        correlation_analysis = {
            "pearson": numeric_data.corr().to_dict(),
            "spearman": numeric_data.corr(method="spearman").to_dict()
        }

        # 4. æå€¼åˆ†æ
        extreme_analysis = {}
        for col in target_cols:
            q1 = numeric_data[col].quantile(0.25)
            q3 = numeric_data[col].quantile(0.75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            outliers = numeric_data[(numeric_data[col] < lower_bound) | (numeric_data[col] > upper_bound)][col]
            extreme_analysis[col] = {
                "iqr": float(iqr),
                "lower_bound": float(lower_bound),
                "upper_bound": float(upper_bound),
                "outlier_count": int(len(outliers)),
                "outlier_rate": float(len(outliers) / len(numeric_data)),
                "min_value": float(numeric_data[col].min()),
                "max_value": float(numeric_data[col].max())
            }

        # æ±‡æ€»åˆ†æç»“æœ
        analysis_result = {
            "basic_info": {
                "sample_count": len(data),
                "feature_count": len(target_cols),
                "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "descriptive_statistics": desc_stats,
            "extended_statistics": extended_stats,
            "normality_test": normality_test,
            "correlation_analysis": correlation_analysis,
            "extreme_analysis": extreme_analysis
        }

        # ä¿å­˜åˆ†æç»“æœ
        save_path = os.path.join(self.output_dir, f"{save_name}.json")
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆå¯é€‰ï¼‰
        if self.plotter:
            # ç”Ÿæˆç»Ÿè®¡å¯è§†åŒ–å›¾è¡¨
            self.plotter.generate_hist_plot(
                data=numeric_data,
                cols=target_cols[:4],
                title="æ•°æ®åˆ†å¸ƒç›´æ–¹å›¾",
                save_name=f"{save_name}_hist"
            )
            self.plotter.generate_heatmap(
                data=numeric_data,
                title="Pearsonç›¸å…³æ€§çƒ­åŠ›å›¾",
                save_name=f"{save_name}_pearson_heatmap"
            )

        # è®°å½•åˆ†æå†å²
        self.analysis_history.append({
            "analysis_type": "basic_statistical",
            "data_shape": data.shape,
            "save_path": save_path,
            "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
        })

        # æ‰“å°å…³é”®ç»“æœ
        print(f"âœ… åŸºç¡€ç»Ÿè®¡åˆ†æå®Œæˆï¼š")
        print(f"  - æ ·æœ¬æ•°ï¼š{len(data)} | ç‰¹å¾æ•°ï¼š{len(target_cols)}")
        print(f"  - å¼‚å¸¸å€¼ç‡ï¼ˆå¹³å‡ï¼‰ï¼š{np.mean([v['outlier_rate'] for v in extreme_analysis.values()]):.3f}")
        print(f"  - æ­£æ€åˆ†å¸ƒç‰¹å¾æ•°ï¼š{sum([1 for v in normality_test.values() if v.get('is_normal', False)])}/{len(target_cols)}")
        print(f"  - åˆ†ææŠ¥å‘Šä¿å­˜ï¼š{save_path}")

        return analysis_result

    def feature_importance_analysis(self, data: pd.DataFrame, target_col: str, **kwargs) -> Dict[str, Any]:
        """
        ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆæ ¸å¿ƒï¼šåŸºäºéšæœºæ£®æ—è¯„ä¼°ç‰¹å¾å¯¹ç›®æ ‡åˆ—çš„è´¡çŒ®ï¼‰
        :param data: å¾…åˆ†ææ•°æ®
        :param target_col: ç›®æ ‡åˆ—å
        :param kwargs: å¯é€‰å‚æ•°ï¼ˆsave_nameï¼šä¿å­˜åï¼‰
        :return: ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ
        """
        print("\nğŸ” å¼€å§‹ç‰¹å¾é‡è¦æ€§åˆ†æ...")
        # è§£æå‚æ•°
        save_name = kwargs.get("save_name", f"feature_importance_{time.strftime('%Y%m%d%H%M%S')}")

        # æ•°æ®é¢„å¤„ç†
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if target_col not in numeric_cols:
            raise ValueError(f"ç›®æ ‡åˆ—{target_col}ä¸æ˜¯æ•°å€¼åˆ—")
        # ç§»é™¤ç›®æ ‡åˆ—ï¼Œä¿ç•™ç‰¹å¾åˆ—
        feature_cols = [col for col in numeric_cols if col != target_col]
        if not feature_cols:
            raise ValueError("æ— å¯ç”¨ç‰¹å¾åˆ—è¿›è¡Œé‡è¦æ€§åˆ†æ")

        # å‡†å¤‡æ•°æ®
        X = data[feature_cols].fillna(data[feature_cols].mean())
        y = data[target_col].fillna(data[target_col].mean())
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X_scaled, y)

        # è®¡ç®—ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.DataFrame({
            "feature": feature_cols,
            "importance": rf_model.feature_importances_,
            "normalized_importance": rf_model.feature_importances_ / rf_model.feature_importances_.sum()
        }).sort_values(by="importance", ascending=False)

        # æ¨¡å‹è¯„ä¼°
        y_pred = rf_model.predict(X_scaled)
        model_metrics = {
            "mae": float(mean_absolute_error(y, y_pred)),
            "r2_score": float(r2_score(y, y_pred)),
            "explained_variance": float(rf_model.score(X_scaled, y))
        }

        # æ±‡æ€»åˆ†æç»“æœ
        analysis_result = {
            "basic_info": {
                "target_column": target_col,
                "feature_count": len(feature_cols),
                "sample_count": len(data),
                "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "feature_importance": feature_importance.to_dict("records"),
            "top_5_features": feature_importance.head(5)["feature"].tolist(),
            "model_metrics": model_metrics
        }

        # ä¿å­˜åˆ†æç»“æœ
        save_path = os.path.join(self.output_dir, f"{save_name}.json")
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆå¯é€‰ï¼‰
        if self.plotter:
            # ç”Ÿæˆç‰¹å¾é‡è¦æ€§æŸ±çŠ¶å›¾
            importance_df = pd.DataFrame({
                "feature": feature_importance["feature"],
                "normalized_importance": feature_importance["normalized_importance"]
            })
            self.plotter.generate_bar_plot(
                data=importance_df.head(10),  # åªæ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
                x_col="feature",
                y_cols=["normalized_importance"],
                title=f"ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆç›®æ ‡åˆ—ï¼š{target_col}ï¼‰",
                xlabel="ç‰¹å¾å",
                ylabel="å½’ä¸€åŒ–é‡è¦æ€§",
                save_name=f"{save_name}_bar"
            )

        # è®°å½•åˆ†æå†å²
        self.analysis_history.append({
            "analysis_type": "feature_importance",
            "target_col": target_col,
            "data_shape": data.shape,
            "save_path": save_path,
            "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
        })

        # æ‰“å°å…³é”®ç»“æœ
        print(f"âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆï¼š")
        print(f"  - ç›®æ ‡åˆ—ï¼š{target_col} | ç‰¹å¾æ•°ï¼š{len(feature_cols)}")
        print(f"  - æ¨¡å‹RÂ²å¾—åˆ†ï¼š{model_metrics['r2_score']:.3f}")
        print(f"  - æœ€é‡è¦çš„5ä¸ªç‰¹å¾ï¼š{', '.join(analysis_result['top_5_features'])}")
        print(f"  - åˆ†ææŠ¥å‘Šä¿å­˜ï¼š{save_path}")

        return analysis_result

    def domain_adaptation_analysis(self, adapt_result: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """
        é¢†åŸŸè‡ªé€‚åº”æ•ˆæœåˆ†æï¼ˆæ ¸å¿ƒï¼šé‡åŒ–è¯„ä¼°æ— ç›‘ç£è‡ªé€‚åº”çš„æ•ˆæœå’Œç¨³å®šæ€§ï¼‰
        :param adapt_result: æ— ç›‘ç£è‡ªé€‚åº”ç»“æœï¼ˆæ¥è‡ªunsupervised_adapt.pyï¼‰
        :param kwargs: å¯é€‰å‚æ•°ï¼ˆsave_nameï¼šä¿å­˜åï¼‰
        :return: é¢†åŸŸè‡ªé€‚åº”åˆ†æç»“æœ
        """
        print("\nğŸŒ å¼€å§‹é¢†åŸŸè‡ªé€‚åº”æ•ˆæœåˆ†æ...")
        # è§£æå‚æ•°
        save_name = kwargs.get("save_name", f"domain_adapt_{time.strftime('%Y%m%d%H%M%S')}")

        # 1. åŸºç¡€ä¿¡æ¯æå–
        domain = adapt_result["domain_match"]["domain"]
        similarity = adapt_result["domain_match"]["similarity"]
        adapt_effect = adapt_result["adapt_effect"]
        adapt_params = adapt_result["adapt_params"]

        # 2. æ•ˆæœé‡åŒ–è¯„ä¼°
        effect_evaluation = {
            "comprehensive_score": adapt_effect["comprehensive_score"],
            "score_grade": self._grade_score(adapt_effect["comprehensive_score"]),
            "key_metrics": {
                "metabolic_stability": {
                    "score": adapt_effect["metabolic_stability"],
                    "grade": self._grade_score(adapt_effect["metabolic_stability"]),
                    "contribution": 0.4  # æƒé‡
                },
                "result_consistency": {
                    "score": adapt_effect["result_consistency"],
                    "grade": self._grade_score(adapt_effect["result_consistency"]),
                    "contribution": 0.2
                },
                "run_efficiency": {
                    "score": adapt_effect["run_efficiency"],
                    "grade": self._grade_score(adapt_effect["run_efficiency"]),
                    "contribution": 0.2
                },
                "performance_rate": {
                    "score": adapt_effect["performance_rate"],
                    "grade": self._grade_score(adapt_effect["performance_rate"]),
                    "contribution": 0.2
                }
            },
            "weighted_score": sum([
                adapt_effect[k] * v["contribution"]
                for k, v in effect_evaluation["key_metrics"].items()
            ])
        }

        # 3. å‚æ•°è°ƒæ•´åˆ†æ
        param_analysis = {}
        # ä»£è°¢å‚æ•°åˆ†æ
        metabolism_params = adapt_params.get("metabolism_params", {})
        param_analysis["metabolism_params"] = {
            "param_count": len(metabolism_params),
            "key_adjustments": self._identify_key_param_changes(metabolism_params),
            "adjustment_range": self._calculate_param_adjustment_range(metabolism_params)
        }
        # ç­–ç•¥å‚æ•°åˆ†æ
        strategy_params = adapt_params.get("strategy_params", {})
        param_analysis["strategy_params"] = {
            "param_count": len(strategy_params),
            "domain_weight": self._get_domain_strategy_weight(strategy_params, domain),
            "max_strategy_weight": max(strategy_params.values()) if strategy_params else 0.0
        }

        # 4. ç¨³å®šæ€§åˆ†æ
        stability_analysis = {
            "domain_similarity": similarity,
            "similarity_grade": self._grade_similarity(similarity),
            "adapt_success": adapt_result["is_adapt_successful"],
            "expected_stability": self._predict_stability(similarity, effect_evaluation["comprehensive_score"])
        }

        # 5. æ”¹è¿›å»ºè®®ç”Ÿæˆ
        improvement_suggestions = self._generate_improvement_suggestions(
            effect_evaluation, stability_analysis, domain
        )

        # æ±‡æ€»åˆ†æç»“æœ
        analysis_result = {
            "basic_info": {
                "domain": domain,
                "domain_similarity": similarity,
                "adapt_time": adapt_result["start_time"],
                "data_sample_count": adapt_result["data_info"]["sample_count"],
                "data_feature_count": len(adapt_result["data_info"]["feature_cols"])
            },
            "effect_evaluation": effect_evaluation,
            "param_analysis": param_analysis,
            "stability_analysis": stability_analysis,
            "improvement_suggestions": improvement_suggestions
        }

        # ä¿å­˜åˆ†æç»“æœ
        save_path = os.path.join(self.output_dir, f"{save_name}.json")
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆå¯é€‰ï¼‰
        if self.plotter:
            self.plotter.generate_adapt_report_plots(adapt_result)

        # è®°å½•åˆ†æå†å²
        self.analysis_history.append({
            "analysis_type": "domain_adaptation",
            "domain": domain,
            "comprehensive_score": effect_evaluation["comprehensive_score"],
            "save_path": save_path,
            "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
        })

        # æ‰“å°å…³é”®ç»“æœ
        print(f"âœ… é¢†åŸŸè‡ªé€‚åº”æ•ˆæœåˆ†æå®Œæˆï¼š")
        print(f"  - åŒ¹é…é¢†åŸŸï¼š{domain}ï¼ˆç›¸ä¼¼åº¦ï¼š{similarity:.3f}ï¼‰")
        print(f"  - ç»¼åˆæ•ˆæœå¾—åˆ†ï¼š{effect_evaluation['comprehensive_score']:.3f}ï¼ˆç­‰çº§ï¼š{effect_evaluation['score_grade']}ï¼‰")
        print(f"  - è‡ªé€‚åº”æˆåŠŸï¼š{stability_analysis['adapt_success']}")
        print(f"  - åˆ†ææŠ¥å‘Šä¿å­˜ï¼š{save_path}")

        return analysis_result

    def multimodal_data_analysis(self, multimodal_data: Dict[str, pd.DataFrame], **kwargs) -> Dict[str, Any]:
        """
        å¤šæ¨¡æ€æ•°æ®èåˆåˆ†æï¼ˆæ ¸å¿ƒï¼šè¯„ä¼°ä¸åŒæ¨¡æ€æ•°æ®çš„ä¸€è‡´æ€§å’Œäº’è¡¥æ€§ï¼‰
        :param multimodal_data: å¤šæ¨¡æ€æ•°æ®å­—å…¸ï¼ˆæ¥è‡ªmultimodal_parser.pyï¼‰
        :param kwargs: å¯é€‰å‚æ•°ï¼ˆsave_nameï¼šä¿å­˜åï¼‰
        :return: å¤šæ¨¡æ€æ•°æ®åˆ†æç»“æœ
        """
        print("\nğŸ­ å¼€å§‹å¤šæ¨¡æ€æ•°æ®èåˆåˆ†æ...")
        # è§£æå‚æ•°
        save_name = kwargs.get("save_name", f"multimodal_analysis_{time.strftime('%Y%m%d%H%M%S')}")

        # 1. åŸºç¡€ä¿¡æ¯ç»Ÿè®¡
        modal_info = {}
        for modality, data in multimodal_data.items():
            modal_info[modality] = {
                "sample_count": len(data),
                "feature_count": len(data.columns),
                "missing_rate": float(data.isnull().sum().sum() / (len(data) * len(data.columns))),
                "data_density": float(len(data.dropna()) / len(data))
            }

        # 2. æ¨¡æ€ä¸€è‡´æ€§åˆ†æ
        consistency_analysis = {}
        # æå–æ‰€æœ‰æ¨¡æ€çš„æ•°å€¼åˆ—å‡å€¼
        modal_means = {}
        for modality, data in multimodal_data.items():
            numeric_data = data.select_dtypes(include=[np.number])
            if not numeric_data.empty:
                modal_means[modality] = numeric_data.mean().mean()  # æ‰€æœ‰åˆ—çš„å‡å€¼çš„å‡å€¼

        # è®¡ç®—æ¨¡æ€é—´çš„ä¸€è‡´æ€§ï¼ˆå˜å¼‚ç³»æ•°ï¼‰
        if len(modal_means) >= 2:
            mean_vals = list(modal_means.values())
            cv = np.std(mean_vals) / np.mean(mean_vals) if np.mean(mean_vals) != 0 else 0.0
            consistency_analysis = {
                "modal_consistency_cv": cv,
                "consistency_grade": self._grade_consistency(cv),
                "modal_means": modal_means,
                "mean_consistency": 1 - cv if cv <= 1 else 0.0
            }
        else:
            consistency_analysis = {"error": "æ¨¡æ€æ•°ä¸è¶³ï¼Œæ— æ³•åˆ†æä¸€è‡´æ€§"}

        # 3. æ¨¡æ€äº’è¡¥æ€§åˆ†æ
        complementarity_analysis = {}
        # è®¡ç®—ä¸åŒæ¨¡æ€ç‰¹å¾çš„é‡å åº¦
        all_features = []
        for modality, data in multimodal_data.items():
            all_features.extend([f"{modality}_{col}" for col in data.columns])
        unique_features = len(set(all_features))
        total_features = len(all_features)
        complementarity_analysis = {
            "feature_overlap_rate": 1 - (unique_features / total_features) if total_features > 0 else 0.0,
            "complementarity_score": unique_features / total_features if total_features > 0 else 0.0,
            "complementarity_grade": self._grade_complementarity(complementarity_analysis["complementarity_score"])
        }

        # 4. èåˆæ•ˆæœè¯„ä¼°
        fusion_evaluation = {
            "data_quality_score": 1 - np.mean([info["missing_rate"] for info in modal_info.values()]),
            "data_quality_grade": self._grade_score(fusion_evaluation["data_quality_score"]),
            "overall_complementarity": complementarity_analysis["complementarity_score"],
            "overall_consistency": consistency_analysis.get("mean_consistency", 0.0),
            "fusion_score": (fusion_evaluation["data_quality_score"] * 0.4 +
                            complementarity_analysis["complementarity_score"] * 0.3 +
                            consistency_analysis.get("mean_consistency", 0.0) * 0.3),
            "fusion_grade": self._grade_score(fusion_evaluation["fusion_score"])
        }

        # æ±‡æ€»åˆ†æç»“æœ
        analysis_result = {
            "basic_info": {
                "modal_count": len(multimodal_data),
                "total_sample_count": sum([info["sample_count"] for info in modal_info.values()]),
                "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "modal_info": modal_info,
            "consistency_analysis": consistency_analysis,
            "complementarity_analysis": complementarity_analysis,
            "fusion_evaluation": fusion_evaluation
        }

        # ä¿å­˜åˆ†æç»“æœ
        save_path = os.path.join(self.output_dir, f"{save_name}.json")
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆå¯é€‰ï¼‰
        if self.plotter:
            self.plotter.generate_multimodal_analysis_plots(multimodal_data)

        # è®°å½•åˆ†æå†å²
        self.analysis_history.append({
            "analysis_type": "multimodal_data",
            "modal_count": len(multimodal_data),
            "fusion_score": fusion_evaluation["fusion_score"],
            "save_path": save_path,
            "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S")
        })

        # æ‰“å°å…³é”®ç»“æœ
        print(f"âœ… å¤šæ¨¡æ€æ•°æ®èåˆåˆ†æå®Œæˆï¼š")
        print(f"  - æ¨¡æ€æ•°ï¼š{len(multimodal_data)} | æ€»æ ·æœ¬æ•°ï¼š{fusion_evaluation['basic_info']['total_sample_count']}")
        print(f"  - èåˆæ•ˆæœå¾—åˆ†ï¼š{fusion_evaluation['fusion_score']:.3f}ï¼ˆç­‰çº§ï¼š{fusion_evaluation['fusion_grade']}ï¼‰")
        print(f"  - æ¨¡æ€äº’è¡¥æ€§ï¼š{complementarity_analysis['complementarity_score']:.3f} | ä¸€è‡´æ€§ï¼š{consistency_analysis.get('mean_consistency', 0.0):.3f}")
        print(f"  - åˆ†ææŠ¥å‘Šä¿å­˜ï¼š{save_path}")

        return analysis_result

    def generate_comprehensive_report(self, analysis_results: List[Dict[str, Any]], **kwargs) -> str:
        """
        ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šï¼ˆæ ¸å¿ƒï¼šæ•´åˆæ‰€æœ‰åˆ†æç»“æœï¼Œè¾“å‡ºäººç±»å¯è¯»çš„markdownæŠ¥å‘Šï¼‰
        :param analysis_results: å„ç±»åˆ†æç»“æœåˆ—è¡¨
        :param kwargs: å¯é€‰å‚æ•°ï¼ˆreport_titleï¼šæŠ¥å‘Šæ ‡é¢˜ï¼‰
        :return: æŠ¥å‘Šä¿å­˜è·¯å¾„
        """
        print("\nğŸ“‹ å¼€å§‹ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
        # è§£æå‚æ•°
        report_title = kwargs.get("report_title", f"UMCæ™ºèƒ½ä½“åˆ†ææŠ¥å‘Š_{time.strftime('%Y%m%d%H%M%S')}")
        save_name = kwargs.get("save_name", f"comprehensive_report_{time.strftime('%Y%m%d%H%M%S')}")

        # æ„å»ºæŠ¥å‘Šå†…å®¹
        report_content = f"""# {report_title}

## æŠ¥å‘Šæ¦‚è§ˆ
- ç”Ÿæˆæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}
- åˆ†æç±»å‹ï¼š{', '.join([r.get('basic_info', {}).get('analysis_type', r.get('analysis_type', 'unknown')) for r in analysis_results])}
- æ•°æ®è§„æ¨¡ï¼š{sum([r.get('basic_info', {}).get('sample_count', 0) for r in analysis_results])} æ ·æœ¬

"""

        # é€ä¸ªæ·»åŠ åˆ†æç»“æœ
        for idx, result in enumerate(analysis_results):
            analysis_type = result.get("analysis_type", f"åˆ†æ{idx+1}")
            report_content += f"## {idx+1}. {self._get_analysis_type_name(analysis_type)}\n\n"

            # åŸºç¡€ç»Ÿè®¡åˆ†æ
            if analysis_type == "basic_statistical":
                report_content += self._format_basic_stats_report(result)
            # ç‰¹å¾é‡è¦æ€§åˆ†æ
            elif analysis_type == "feature_importance":
                report_content += self._format_feature_importance_report(result)
            # é¢†åŸŸè‡ªé€‚åº”åˆ†æ
            elif analysis_type == "domain_adaptation":
                report_content += self._format_domain_adapt_report(result)
            # å¤šæ¨¡æ€æ•°æ®åˆ†æ
            elif analysis_type == "multimodal_data":
                report_content += self._format_multimodal_report(result)
            # é€šç”¨æ ¼å¼
            else:
                report_content += f"### å…³é”®æŒ‡æ ‡\n"
                for k, v in result.get("basic_info", {}).items():
                    report_content += f"- {k}ï¼š{v}\n"
                report_content += "\n"

        # æ·»åŠ æ€»ç»“å’Œå»ºè®®
        report_content += f"""## æ€»ç»“ä¸å»ºè®®

### æ ¸å¿ƒç»“è®º
"""
        # æå–å…³é”®ç»“è®º
        for result in analysis_results:
            if "effect_evaluation" in result:
                score = result["effect_evaluation"]["comprehensive_score"]
                grade = result["effect_evaluation"]["score_grade"]
                report_content += f"- é¢†åŸŸè‡ªé€‚åº”æ•ˆæœï¼š{score:.3f}ï¼ˆ{grade}ï¼‰\n"
            elif "fusion_evaluation" in result:
                score = result["fusion_evaluation"]["fusion_score"]
                grade = result["fusion_evaluation"]["fusion_grade"]
                report_content += f"- å¤šæ¨¡æ€èåˆæ•ˆæœï¼š{score:.3f}ï¼ˆ{grade}ï¼‰\n"
            elif "model_metrics" in result:
                r2 = result["model_metrics"]["r2_score"]
                report_content += f"- ç‰¹å¾é‡è¦æ€§æ¨¡å‹è§£é‡Šåº¦ï¼š{r2:.3f}\n"

        report_content += f"""
### æ”¹è¿›å»ºè®®
1. é’ˆå¯¹å¾—åˆ†è¾ƒä½çš„æŒ‡æ ‡ï¼ˆ<0.7ï¼‰ï¼Œå»ºè®®è°ƒæ•´å¯¹åº”çš„è‡ªé€‚åº”å‚æ•°
2. å¤šæ¨¡æ€æ•°æ®è‹¥ä¸€è‡´æ€§è¾ƒä½ï¼Œå»ºè®®å¢åŠ æ ·æœ¬é‡æˆ–ä¼˜åŒ–ç‰¹å¾æå–é€»è¾‘
3. ç‰¹å¾é‡è¦æ€§è¾ƒä½çš„åˆ—å¯è€ƒè™‘ç§»é™¤ï¼Œæå‡æ™ºèƒ½ä½“è¿è¡Œæ•ˆç‡
4. å®šæœŸé‡æ–°è¯„ä¼°é¢†åŸŸè‡ªé€‚åº”æ•ˆæœï¼Œç¡®ä¿é•¿æœŸç¨³å®šæ€§

---
*æŠ¥å‘Šç”±UMC-Metabolic-Agentè‡ªåŠ¨ç”Ÿæˆ*
"""

        # ä¿å­˜æŠ¥å‘Š
        save_path = os.path.join(self.output_dir, f"{save_name}.md")
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print(f"âœ… ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼š{save_path}")
        return save_path

    # ------------------------------ è¾…åŠ©æ–¹æ³• ------------------------------
    def _grade_score(self, score: float) -> str:
        """ç»™å¾—åˆ†è¯„çº§ï¼ˆ0~1ï¼‰"""
        if score >= 0.9:
            return "ä¼˜ç§€"
        elif score >= 0.8:
            return "è‰¯å¥½"
        elif score >= 0.7:
            return "ä¸­ç­‰"
        elif score >= 0.6:
            return "åŠæ ¼"
        else:
            return "å¾…ä¼˜åŒ–"

    def _grade_similarity(self, similarity: float) -> str:
        """ç»™é¢†åŸŸç›¸ä¼¼åº¦è¯„çº§ï¼ˆ0~1ï¼‰"""
        if similarity >= 0.8:
            return "æé«˜"
        elif similarity >= 0.7:
            return "é«˜"
        elif similarity >= 0.6:
            return "ä¸­ç­‰"
        elif similarity >= 0.5:
            return "ä½"
        else:
            return "æä½"

    def _grade_consistency(self, cv: float) -> str:
        """ç»™ä¸€è‡´æ€§è¯„çº§ï¼ˆå˜å¼‚ç³»æ•°ï¼‰"""
        if cv <= 0.1:
            return "æé«˜"
        elif cv <= 0.2:
            return "é«˜"
        elif cv <= 0.3:
            return "ä¸­ç­‰"
        elif cv <= 0.4:
            return "ä½"
        else:
            return "æä½"

    def _grade_complementarity(self, score: float) -> str:
        """ç»™äº’è¡¥æ€§è¯„çº§ï¼ˆ0~1ï¼‰"""
        if score >= 0.9:
            return "æé«˜"
        elif score >= 0.8:
            return "é«˜"
        elif score >= 0.7:
            return "ä¸­ç­‰"
        elif score >= 0.6:
            return "ä½"
        else:
            return "æä½"

    def _identify_key_param_changes(self, params: Dict[str, float]) -> List[str]:
        """è¯†åˆ«å…³é”®å‚æ•°è°ƒæ•´"""
        if not params:
            return []
        # å‡è®¾åŸºå‡†å€¼ä¸º0.5ï¼Œè¶…è¿‡Â±0.1è§†ä¸ºå…³é”®è°ƒæ•´
        key_changes = []
        for param, value in params.items():
            if abs(value - 0.5) >= 0.1:
                key_changes.append(f"{param}ï¼ˆ{value:.3f}ï¼‰")
        return key_changes if key_changes else ["æ— æ˜¾è‘—è°ƒæ•´"]

    def _calculate_param_adjustment_range(self, params: Dict[str, float]) -> Dict[str, float]:
        """è®¡ç®—å‚æ•°è°ƒæ•´èŒƒå›´"""
        if not params:
            return {"min": 0.0, "max": 0.0, "range": 0.0}
        values = list(params.values())
        return {
            "min": min(values),
            "max": max(values),
            "range": max(values) - min(values)
        }

    def _get_domain_strategy_weight(self, strategy_params: Dict[str, float], domain: str) -> float:
        """è·å–é¢†åŸŸç­–ç•¥æƒé‡"""
        domain_key = None
        for key in strategy_params.keys():
            if domain in key or key == "unknown_domain":
                domain_key = key
                break
        return strategy_params.get(domain_key, 0.0) if domain_key else 0.0

    def _predict_stability(self, similarity: float, score: float) -> float:
        """é¢„æµ‹é•¿æœŸç¨³å®šæ€§"""
        return (similarity * 0.6 + score * 0.4)  # ç›¸ä¼¼åº¦60%æƒé‡ï¼Œæ•ˆæœå¾—åˆ†40%æƒé‡

    def _generate_improvement_suggestions(self, effect: Dict[str, Any], stability: Dict[str, Any], domain: str) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        score = effect["comprehensive_score"]

        if score < 0.7:
            suggestions.append(f"{domain}é¢†åŸŸè‡ªé€‚åº”æ•ˆæœå¾…ä¼˜åŒ–ï¼ˆç»¼åˆå¾—åˆ†{score:.3f}ï¼‰ï¼Œå»ºè®®ï¼š")
            # åˆ†æä½åˆ†æŒ‡æ ‡
            low_metrics = [k for k, v in effect["key_metrics"].items() if v["score"] < 0.7]
            if "metabolic_stability" in low_metrics:
                suggestions.append("- è°ƒæ•´ä»£è°¢ç¨³å®šæ€§é˜ˆå€¼å‚æ•°ï¼Œæé«˜æ ¸å¿ƒå› å­æƒé‡")
            if "result_consistency" in low_metrics:
                suggestions.append("- å¢åŠ å¤šæ¬¡è¿è¡Œçš„æ ·æœ¬é‡ï¼Œä¼˜åŒ–ä¸€è‡´æ€§è®¡ç®—é€»è¾‘")
            if "run_efficiency" in low_metrics:
                suggestions.append("- é™ä½å¾ªç¯é€Ÿåº¦ï¼Œå‡å°‘ä¸å¿…è¦çš„è¿­ä»£æ¬¡æ•°")
            if "performance_rate" in low_metrics:
                suggestions.append("- è°ƒæ•´æ€§èƒ½é˜ˆå€¼ï¼Œé€‚é…å½“å‰é¢†åŸŸæ•°æ®ç‰¹å¾")
        else:
            suggestions.append(f"{domain}é¢†åŸŸè‡ªé€‚åº”æ•ˆæœè‰¯å¥½ï¼ˆç»¼åˆå¾—åˆ†{score:.3f}ï¼‰ï¼Œå»ºè®®ä¿æŒå½“å‰å‚æ•°é…ç½®")

        if stability["similarity_grade"] in ["ä½", "æä½"]:
            suggestions.append(f"é¢†åŸŸåŒ¹é…ç›¸ä¼¼åº¦è¾ƒä½ï¼ˆ{stability['domain_similarity']:.3f}ï¼‰ï¼Œå»ºè®®æ‰©å±•é¢†åŸŸç‰¹å¾åº“")

        return suggestions

    def _get_analysis_type_name(self, analysis_type: str) -> str:
        """è·å–åˆ†æç±»å‹çš„ä¸­æ–‡åç§°"""
        type_mapping = {
            "basic_statistical": "åŸºç¡€ç»Ÿè®¡åˆ†æ",
            "feature_importance": "ç‰¹å¾é‡è¦æ€§åˆ†æ",
            "domain_adaptation": "é¢†åŸŸè‡ªé€‚åº”æ•ˆæœåˆ†æ",
            "multimodal_data": "å¤šæ¨¡æ€æ•°æ®èåˆåˆ†æ"
        }
        return type_mapping.get(analysis_type, analysis_type)

    def _format_basic_stats_report(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–åŸºç¡€ç»Ÿè®¡åˆ†ææŠ¥å‘Š"""
        content = f"""### æ•°æ®åŸºæœ¬ä¿¡æ¯
- æ ·æœ¬æ•°é‡ï¼š{result['basic_info']['sample_count']}
- ç‰¹å¾æ•°é‡ï¼š{result['basic_info']['feature_count']}

### å…³é”®ç»Ÿè®¡æŒ‡æ ‡
| ç‰¹å¾ | å‡å€¼ | ä¸­ä½æ•° | å˜å¼‚ç³»æ•° | ç¼ºå¤±ç‡ | å¼‚å¸¸å€¼ç‡ |
|------|------|--------|----------|--------|----------|
"""
        for col, stats in result["descriptive_statistics"].items():
            extended = result["extended_statistics"][col]
            extreme = result["extreme_analysis"][col]
            content += f"| {col} | {stats['mean']:.3f} | {extended['median']:.3f} | {extended['cv']:.3f} | {extended['missing_rate']:.3f} | {extreme['outlier_rate']:.3f} |\n"

        content += f"""
### åˆ†å¸ƒæ£€éªŒç»“æœ
| ç‰¹å¾ | æ­£æ€æ€§på€¼ | æ˜¯å¦æ­£æ€åˆ†å¸ƒ |
|------|-----------|--------------|
"""
        for col, test in result["normality_test"].items():
            if "p_value" in test:
                content += f"| {col} | {test['p_value']:.3f} | {'æ˜¯' if test['is_normal'] else 'å¦'} |\n"
            else:
                content += f"| {col} | - | {test['error']} |\n"

        content += "\n"
        return content

    def _format_feature_importance_report(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š"""
        content = f"""### åˆ†æé…ç½®
- ç›®æ ‡åˆ—ï¼š{result['basic_info']['target_column']}
- ç‰¹å¾æ•°é‡ï¼š{result['basic_info']['feature_count']}
- æ¨¡å‹RÂ²å¾—åˆ†ï¼š{result['model_metrics']['r2_score']:.3f}

### ç‰¹å¾é‡è¦æ€§æ’åï¼ˆå‰5ï¼‰
| æ’å | ç‰¹å¾å | å½’ä¸€åŒ–é‡è¦æ€§ |
|------|--------|--------------|
"""
        for idx, item in enumerate(result["top_5_features"][:5]):
            importance = next((f["normalized_importance"] for f in result["feature_importance"] if f["feature"] == item), 0.0)
            content += f"| {idx+1} | {item} | {importance:.3f} |\n"

        content += "\n"
        return content

    def _format_domain_adapt_report(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–é¢†åŸŸè‡ªé€‚åº”åˆ†ææŠ¥å‘Š"""
        content = f"""### è‡ªé€‚åº”åŸºç¡€ä¿¡æ¯
- åŒ¹é…é¢†åŸŸï¼š{result['basic_info']['domain']}
- é¢†åŸŸç›¸ä¼¼åº¦ï¼š{result['basic_info']['domain_similarity']:.3f}ï¼ˆ{result['stability_analysis']['similarity_grade']}ï¼‰
- æ•°æ®æ ·æœ¬æ•°ï¼š{result['basic_info']['data_sample_count']}

### æ•ˆæœè¯„ä¼°ç»“æœ
| æŒ‡æ ‡ | å¾—åˆ† | ç­‰çº§ | æƒé‡ |
|------|------|------|------|
"""
        for metric, info in result["effect_evaluation"]["key_metrics"].items():
            content += f"| {metric} | {info['score']:.3f} | {info['grade']} | {info['contribution']} |\n"

        content += f"""
- ç»¼åˆå¾—åˆ†ï¼š{result['effect_evaluation']['comprehensive_score']:.3f}ï¼ˆ{result['effect_evaluation']['score_grade']}ï¼‰
- è‡ªé€‚åº”æˆåŠŸï¼š{result['stability_analysis']['adapt_success']}

### æ”¹è¿›å»ºè®®
"""
        for suggestion in result["improvement_suggestions"]:
            content += f"- {suggestion}\n"

        content += "\n"
        return content

    def _format_multimodal_report(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å¤šæ¨¡æ€æ•°æ®åˆ†ææŠ¥å‘Š"""
        content = f"""### æ¨¡æ€åŸºæœ¬ä¿¡æ¯
| æ¨¡æ€ | æ ·æœ¬æ•° | ç‰¹å¾æ•° | ç¼ºå¤±ç‡ | æ•°æ®å¯†åº¦ |
|------|--------|--------|--------|----------|
"""
        for modal, info in result["modal_info"].items():
            content += f"| {modal} | {info['sample_count']} | {info['feature_count']} | {info['missing_rate']:.3f} | {info['data_density']:.3f} |\n"

        content += f"""
### èåˆæ•ˆæœè¯„ä¼°
- èåˆæ•ˆæœå¾—åˆ†ï¼š{result['fusion_evaluation']['fusion_score']:.3f}ï¼ˆ{result['fusion_evaluation']['fusion_grade']}ï¼‰
- æ•°æ®è´¨é‡å¾—åˆ†ï¼š{result['fusion_evaluation']['data_quality_score']:.3f}ï¼ˆ{result['fusion_evaluation']['data_quality_grade']}ï¼‰
- æ¨¡æ€äº’è¡¥æ€§ï¼š{result['complementarity_analysis']['complementarity_score']:.3f}ï¼ˆ{result['complementarity_analysis']['complementarity_grade']}ï¼‰
"""
        if "mean_consistency" in result["consistency_analysis"]:
            content += f"- æ¨¡æ€ä¸€è‡´æ€§ï¼š{result['consistency_analysis']['mean_consistency']:.3f}ï¼ˆ{self._grade_consistency(1 - result['consistency_analysis']['mean_consistency'])}ï¼‰\n"

        content += "\n"
        return content

# ç»“æœåˆ†ææ¨¡å—éªŒè¯å…¥å£ï¼ˆä¸€ç«™å¼æµ‹è¯•ï¼‰
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–ç»“æœåˆ†æå™¨
    analyzer = ResultAnalyzer()
    print("ğŸš€ ç»“æœåˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼")

    # 2. ç”Ÿæˆæµ‹è¯•æ•°æ®
    # åŸºç¡€ç»Ÿè®¡åˆ†ææµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        "qubit_stability": np.random.rand(100)*0.9,
        "energy_consumption": np.random.rand(100)*0.8,
        "matter_output": np.random.rand(100)*0.7,
        "noise": np.random.normal(0, 1, 100)  # æ­£æ€åˆ†å¸ƒæ•°æ®
    })
    # æ’å…¥ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
    test_data.loc[10:15, "qubit_stability"] = np.nan
    test_data.loc[20, "energy_consumption"] = 5.0  # å¼‚å¸¸å€¼

    # ç‰¹å¾é‡è¦æ€§åˆ†ææµ‹è¯•æ•°æ®
    target_col = "matter_output"

    # é¢†åŸŸè‡ªé€‚åº”ç»“æœæµ‹è¯•æ•°æ®
    test_adapt_result = {
        "start_time": "2026-01-01 12:00:00",
        "end_time": "2026-01-01 12:05:00",
        "total_duration": "300.00s",
        "data_info": {"sample_count": 200, "feature_cols": ["qubit_stability", "energy_consumption", "matter_output"]},
        "domain_match": {"domain": "quantum", "similarity": 0.85},
        "adapt_params": {
            "domain": "quantum",
            "adapt_time": "2026-01-01 12:02:00",
            "metabolism_params": {"core_factor_weight": 0.88, "stability_threshold": 0.85, "cycle_speed": 0.09},
            "strategy_params": {"qubit_stability": 0.9, "atomic_frequency": 0.5, "logistics_efficiency": 0.5},
            "agi_l3_params": {"goal_discovery_threshold": 0.45}
        },
        "adapt_effect": {
            "metabolic_stability": 0.88,
            "result_consistency": 0.92,
            "run_efficiency": 0.85,
            "performance_rate": 0.89,
            "comprehensive_score": 0.88
        },
        "is_adapt_successful": True
    }

    # å¤šæ¨¡æ€æ•°æ®æµ‹è¯•æ•°æ®
    test_multimodal_data = {
        "table": pd.DataFrame({
            "feature1": np.random.rand(50)*0.9,
            "feature2": np.random.rand(50)*0.8,
            "feature3": np.random.rand(50)*0.7
        }),
        "text": pd.DataFrame({
            "qubit_stability": np.random.rand(10)*0.9,
            "energy_consumption": np.random.rand(10)*0.8,
            "matter_output": np.random.rand(10)*0.7
        }),
        "timeseries": pd.DataFrame({
            "ts_feature1": np.random.rand(30)*0.9,
            "ts_feature2": np.random.rand(30)*0.8
        })
    }

    # 3. æ‰§è¡Œå„ç±»åˆ†æ
    # åŸºç¡€ç»Ÿè®¡åˆ†æ
    basic_result = analyzer.basic_statistical_analysis(test_data, target_cols=["qubit_stability", "energy_consumption", "matter_output"])

    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    feature_result = analyzer.feature_importance_analysis(test_data, target_col="matter_output")

    # é¢†åŸŸè‡ªé€‚åº”åˆ†æ
    adapt_result = analyzer.domain_adaptation_analysis(test_adapt_result)

    # å¤šæ¨¡æ€æ•°æ®åˆ†æ
    multimodal_result = analyzer.multimodal_data_analysis(test_multimodal_data)

    # 4. ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
    all_results = [basic_result, feature_result, adapt_result, multimodal_result]
    report_path = analyzer.generate_comprehensive_report(all_results, report_title="UMCæ™ºèƒ½ä½“æµ‹è¯•åˆ†ææŠ¥å‘Š")

    # 5. æŸ¥çœ‹åˆ†æå†å²
    print("\nğŸ“œ åˆ†æå†å²æ±‡æ€»ï¼š")
    for idx, history in enumerate(analyzer.analysis_history):
        print(f"  {idx+1}. ç±»å‹ï¼š{history['analysis_type']} | è·¯å¾„ï¼š{history['save_path']}")

    print(f"\nğŸ‰ ç»“æœåˆ†ææ¨¡å—æµ‹è¯•å®Œæˆï¼")
    print(f"  - ç»¼åˆåˆ†ææŠ¥å‘Šï¼š{report_path}")
    print(f"  - æ‰€æœ‰åˆ†æç»“æœå·²ä¿å­˜è‡³ ./analysis_reports")
    print(f"  - åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³ ./analysis_plotsï¼ˆè‹¥å¯ç”¨å¯è§†åŒ–ï¼‰")